{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Please build a baseline classification model then run a few experiments with different optimizers and learning rates. \n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "### Write a function to load your data\n",
    "\n",
    "Wrap yesterday's preprocessing steps into a function that returns four items:\n",
    "* X_train\n",
    "* y_train\n",
    "* X_test\n",
    "* y_test\n",
    "\n",
    "Your function should accept a `path` to the data as a argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from sklearn.utils import shuffle\n",
    "#data = np.load('../quickdraw10.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data['arr_0']\n",
    "temp[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJsIsrvp7O3e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_quickdraw10(path):\n",
    "    data = np.load('../quickdraw10.npz')\n",
    "    X = data['arr_0']\n",
    "    y = data['arr_1']\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    length = len(data['arr_0'])\n",
    "    ratio = int(length * .8)\n",
    "    \n",
    "    X_train = X[0:ratio]\n",
    "    y_train = y[0:ratio]\n",
    "    X_test =  X[ratio:length]\n",
    "    y_test = y[ratio:length]\n",
    "    #print(len(X_train), len(y_train), len(X_test), len(y_test))\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y test_size=0.20, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([0, 0, 0, ..., 7, 7, 7], dtype=int64),\n",
       " array([8, 8, 8, ..., 9, 9, 9], dtype=int64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_quickdraw10('../quickdraw10.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-6PxI6H5__2"
   },
   "source": [
    "### Write a Model Function\n",
    "Using your model from yesterday, write a function called `create_model` which returns a compiled TensorFlow Keras Sequential Model suitable for classifying the QuickDraw-10 dataset. Include parameters for the following: \n",
    "* Learning Rate\n",
    "* Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def create_model(learning_rate=.0001, optimizer=tf.keras.optimizers.Adam()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=784, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(125, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    optimizer.learning_rate = learning_rate\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_quickdraw10('../quickdraw10.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0pCkh8C7eGL"
   },
   "source": [
    "### Experiment with Batch Size\n",
    "* Run 5 experiments with various batch sizes of your choice. \n",
    "* Visualize the results\n",
    "* Write up an analysis of the experiments and select the \"best\" performing model among your experiments. Make sure to compare against your model's performance yesterday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.9469 - accuracy: 0.6453\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8574 - accuracy: 0.7583\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.6146 - accuracy: 0.8149\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.4909 - accuracy: 0.8478\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.4057 - accuracy: 0.8723\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "### Experiment with Learning Rate\n",
    "* Run 5 experiments with various learning rate magnitudes: 1, .1, .01, .001, .0001.\n",
    "* Use the \"best\" batch size from the previous experiment\n",
    "* Visualize the results\n",
    "* Write up an analysis of the experiments and select the \"best\" performing model among your experiments. Make sure to compare against the previous experiments and your model's performance yesterday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SA144xx8Luf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 5.3208 - accuracy: 0.2277\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3470 - accuracy: 0.5380\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.1753 - accuracy: 0.5986\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.1572 - accuracy: 0.6072\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.1616 - accuracy: 0.6169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2315ac0e940>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.005).fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2805 - accuracy: 0.7455\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.5875 - accuracy: 0.8234\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.4968 - accuracy: 0.8490\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.4348 - accuracy: 0.8680\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3861 - accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2315c7bd940>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.0005).fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.1974 - accuracy: 0.6538\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0186 - accuracy: 0.7467\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.7126 - accuracy: 0.7992\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.5491 - accuracy: 0.8361\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.4463 - accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23169cd0970>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.00005).fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 13.4375 - accuracy: 0.4750\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 6.5938 - accuracy: 0.6048\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.8454 - accuracy: 0.6477\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.8448 - accuracy: 0.6756\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.1943 - accuracy: 0.6952\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.7272 - accuracy: 0.7108\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.3720 - accuracy: 0.7237\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.0927 - accuracy: 0.7356\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8663 - accuracy: 0.7469\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6794 - accuracy: 0.7574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23172b3aa60>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.000005).fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 49.5249 - accuracy: 0.1543\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 29.2980 - accuracy: 0.2582\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 22.8244 - accuracy: 0.3450\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 19.0599 - accuracy: 0.4034\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 16.5135 - accuracy: 0.4453\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 14.6557 - accuracy: 0.4776\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 13.2266 - accuracy: 0.5034\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 12.0867 - accuracy: 0.5242\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 11.1475 - accuracy: 0.5404\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 10.3588 - accuracy: 0.5533\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 9.6793 - accuracy: 0.5645\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 9.0883 - accuracy: 0.5744\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 8.5725 - accuracy: 0.5839\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 8.1144 - accuracy: 0.5903\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 7.7030 - accuracy: 0.5973\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 7.3292 - accuracy: 0.6033\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 6.9899 - accuracy: 0.6092\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 6.6789 - accuracy: 0.6146\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 6.3964 - accuracy: 0.6197\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 6.1398 - accuracy: 0.6240\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 5.9050 - accuracy: 0.6285\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 5.6888 - accuracy: 0.6323\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 5.4894 - accuracy: 0.6363\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 5.3032 - accuracy: 0.6400\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 5.1292 - accuracy: 0.6439\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.9652 - accuracy: 0.6458\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.8109 - accuracy: 0.6495\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.6674 - accuracy: 0.6523\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.5327 - accuracy: 0.6554\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.4048 - accuracy: 0.6583\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 4.2833 - accuracy: 0.66 - 4s 2ms/step - loss: 4.2845 - accuracy: 0.6611\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.1698 - accuracy: 0.6636\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 4.0606 - accuracy: 0.6660\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.9574 - accuracy: 0.6683\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.8587 - accuracy: 0.6702\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.7641 - accuracy: 0.6729\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.6743 - accuracy: 0.6755\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.5881 - accuracy: 0.6773\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.5073 - accuracy: 0.6796\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.4293 - accuracy: 0.6814\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.3551 - accuracy: 0.6833\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.2844 - accuracy: 0.6857\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.2170 - accuracy: 0.6877\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.1520 - accuracy: 0.6896\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.0896 - accuracy: 0.6916\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 3.0296 - accuracy: 0.6936\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.9719 - accuracy: 0.6953\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.9171 - accuracy: 0.6974\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.8640 - accuracy: 0.6986\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.8130 - accuracy: 0.7002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23174338c70>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.0000005).fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would seem that the models performance increases the lower the learning rate, but you will need to train the model\n",
    "# for substantially more training iterations to make up for the lower learning rate.\n",
    "# Basically, there is a tradeoff between model performance and how many iterations the model must train for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxMtSRhV9Q7I"
   },
   "source": [
    "### Experiment with different Optimizers\n",
    "* Run 5 experiments with various optimizers available in TensorFlow. See list [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
    "* Visualize the results\n",
    "* Write up an analysis of the experiments and select the \"best\" performing model among your experiments. Make sure to compare against the previous experiments and your model's performance yesterday.\n",
    "* Repeat the experiment combining Learning Rate and different optimizers. Does the best performing model change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujLuzdNA91ip"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8310 - accuracy: 0.6109\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.8667 - accuracy: 0.7286\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7543 - accuracy: 0.7661\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.6898 - accuracy: 0.7862\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.6436 - accuracy: 0.7996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23175271a00>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.0005, optimizer=tf.keras.optimizers.SGD()).fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 54.8442 - accuracy: 0.1392\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 28.0409 - accuracy: 0.2449\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 21.1659 - accuracy: 0.3365\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 17.4899 - accuracy: 0.3930\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 15.1058 - accuracy: 0.4340\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 13.4236 - accuracy: 0.4627\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 12.1537 - accuracy: 0.4853\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 11.1524 - accuracy: 0.5034\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 10.3412 - accuracy: 0.5196\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 9.6692 - accuracy: 0.5324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23169ff3220>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.0005, optimizer=tf.keras.optimizers.Adadelta()).fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.7904 - accuracy: 0.6735\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.7107 - accuracy: 0.7914\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.5315 - accuracy: 0.8390\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.4358 - accuracy: 0.8658\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3682 - accuracy: 0.8862\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3128 - accuracy: 0.9035\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2673 - accuracy: 0.9172\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2264 - accuracy: 0.9302\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9411\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1617 - accuracy: 0.9508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231783219a0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.0005, optimizer=tf.keras.optimizers.Adamax()).fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.7465 - accuracy: 0.6848\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.9450 - accuracy: 0.7573\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9166 - accuracy: 0.7699\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.9767 - accuracy: 0.7609\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0627 - accuracy: 0.7469\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.1481 - accuracy: 0.7284\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.2157 - accuracy: 0.7051\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 1.2930 - accuracy: 0.6661\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4114 - accuracy: 0.6497\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4279 - accuracy: 0.6475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23178aa6bb0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(learning_rate=.0005, optimizer=tf.keras.optimizers.RMSprop()).fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydAqeY9S8uHA"
   },
   "source": [
    "### Additional Written Tasks\n",
    "\n",
    "1. Describe the process of backpropagation in your own words: \n",
    "```\n",
    "It is a function that calculates that gradient of error for a function and attempts to find any local\n",
    "minima / maxima of error for any given function. \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Implement GridSearch on anyone of the experiments\n",
    "- On the learning rate experiments, implement [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
    "- Review material on the math behind gradient descent: \n",
    "\n",
    "  - Gradient Descent\n",
    "    - Gradient Descent, Step-by-Step  by StatQuest w/ Josh Starmer. This will help you understand the gradient descent based optimization that happens underneath the hood of neural networks. It uses a non-neural network example, which I believe is a gentler introduction. You will hear me refer to this technique as \"vanilla\" gradient descent. \n",
    "    - Stochastic Gradient Descent, Clearly Explained!!! by StatQuest w/ Josh Starmer. This builds on the techniques in the previous video.  This technique is the one that is actually implemented inside modern 'nets. \n",
    "These are great resources to help you understand tomorrow's material at a deeper level. I highly recommend watching these ahead of tomorrow.\n",
    "\n",
    "  - Background Math\n",
    "    - Dot products and duality by 3Blue1Brown. Explains the core linear algebra operation happening in today's perceptron.\n",
    "The paradox of the derivative by 3Blue1Brown. Does a great job explaining a derivative. \n",
    "    - Visualizing the chain rule and product rule by 3Blue1Brown. Explains the black magic that happens within Stochastic Gradient Descent. \n",
    "These math resources are very much optional. They can be very heady, but I encourage you to explore. Your understanding of neural networks will greatly increase if you understand this math background.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_432_Train_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
